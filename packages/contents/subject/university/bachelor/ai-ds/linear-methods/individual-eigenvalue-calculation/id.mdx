export const metadata = {
    title: "Perhitungan Nilai Eigen Individu",
    authors: [{ name: "Nabil Akbarazzima Fatih" }],
    date: "07/17/2025",
    subject: "Metode Linear AI",
};

## Metode Iterasi Invers dengan Pergeseran

Metode iterasi invers dengan pergeseran dirancang untuk menghitung nilai eigen spesifik yang mendekati tebakan awal. Algoritma ini menggunakan parameter pergeseran <InlineMath math="\mu" /> sebagai panduan pencarian menuju nilai eigen tertentu.

Bayangkan kamu mencari stasiun radio di tengah banyak frekuensi. Tanpa pergeseran, kamu mendengar semua stasiun sekaligus (tidak jelas). Dengan pergeseran, kamu mengarahkan dial ke frekuensi tertentu untuk mendapatkan satu stasiun yang jernih.

Algoritma dimulai dengan matriks <InlineMath math="A \in \mathbb{R}^{n \times n}" /> dan parameter pergeseran <InlineMath math="\mu \in \mathbb{R}" />. Vektor awal <InlineMath math="w_0 \in \mathbb{R}^n" /> dinormalisasi menjadi <InlineMath math="\hat{w}_0 := w_0/\|w_0\|" /> dan iterasi dimulai dari <InlineMath math="k := 0" />.

### Dekomposisi LU dan Iterasi

Langkah pertama adalah menghitung dekomposisi LU dari matriks <InlineMath math="A - \mu \cdot I" />. Dekomposisi ini dilakukan sekali di awal dan digunakan berulang dalam setiap iterasi untuk efisiensi komputasi.

<MathContainer>
<BlockMath math="w_{k+1} := (A - \mu \cdot I)^{-1} \cdot \hat{w}_k" />
</MathContainer>

Praktiknya, alih-alih menghitung invers matriks langsung, kita menyelesaikan sistem persamaan linear menggunakan dekomposisi LU

<MathContainer>
<BlockMath math="(A - \mu \cdot I) \cdot w_{k+1} = \hat{w}_k" />
</MathContainer>

### Normalisasi dan Konvergensi

Setelah memperoleh <InlineMath math="w_{k+1}" />, lakukan normalisasi untuk mencegah pertumbuhan tak terkendali

<MathContainer>
<BlockMath math="\hat{w}_{k+1} := w_{k+1}/\|w_{k+1}\|" />
</MathContainer>

Estimasi nilai eigen menggunakan rasio komponen vektor. Untuk indeks <InlineMath math="j" /> dengan <InlineMath math="(\hat{w}_k)_j \neq 0" />

<MathContainer>
<BlockMath math="\lambda := (w_{k+1})_j / (\hat{w}_k)_j" />
</MathContainer>

Iterasi berlanjut hingga memenuhi kriteria konvergensi <InlineMath math="|1/\lambda - 1/\lambda_{\text{lama}}| \leq \text{toleransi}" />. Parameter toleransi adalah nilai ambang batas yang menentukan seberapa akurat hasil yang diinginkan, misalnya <InlineMath math="10^{-6}" /> untuk akurasi enam digit desimal. 

Bayangkan seperti mengukur tinggi badan dengan penggaris. Toleransi menentukan seberapa presisi pengukuran yang kamu terima (apakah cukup akurat sampai centimeter, atau perlu sampai milimeter). Semakin kecil nilai toleransi, semakin akurat hasilnya, tetapi memerlukan lebih banyak iterasi.

Hasil akhir memberikan nilai eigen <InlineMath math="1/\lambda + \mu" /> dan vektor eigen <InlineMath math="\hat{w}_k" />.

## Metode von Mises untuk Nilai Eigen Dominan

Metode iterasi vektor von Mises menemukan nilai eigen dengan magnitudo terbesar (nilai eigen dominan). Algoritma ini menggunakan proses iterasi sederhana dengan perkalian matriks berulang.

Algoritma dimulai dengan vektor awal <InlineMath math="w_0 \in \mathbb{R}^n" /> yang dinormalisasi <InlineMath math="\hat{w}_0 := w_0/\|w_0\|" /> dan iterasi dimulai dari <InlineMath math="k := 0" />.

### Iterasi dan Konvergensi

Setiap iterasi melakukan dua operasi utama

<MathContainer>
<BlockMath math="w_{k+1} := A \cdot \hat{w}_k" />
<BlockMath math="\hat{w}_{k+1} := w_{k+1}/\|w_{k+1}\|" />
</MathContainer>

Estimasi nilai eigen menggunakan rasio komponen untuk indeks <InlineMath math="j" /> dengan <InlineMath math="(\hat{w}_k)_j \neq 0" />

<MathContainer>
<BlockMath math="\lambda := (w_{k+1})_j / (\hat{w}_k)_j" />
</MathContainer>

Iterasi berlanjut hingga <InlineMath math="|\lambda - \lambda_{\text{lama}}| \leq \text{toleransi}" />. Nilai toleransi menentukan tingkat ketelitian yang dibutuhkan, biasanya berkisar antara <InlineMath math="10^{-8}" /> hingga <InlineMath math="10^{-12}" /> untuk perhitungan presisi tinggi. Hasil akhir adalah nilai eigen dominan <InlineMath math="\lambda" /> dan vektor eigen <InlineMath math="\hat{w}_k" />.

Metode ini berhasil jika <InlineMath math="|\lambda_1| > |\lambda_2|" /> dan vektor awal <InlineMath math="w_0" /> memiliki komponen tidak nol dalam arah vektor eigen dominan. Dengan asumsi tersebut, iterasi konvergen ke nilai eigen dominan <InlineMath math="\lambda_1" /> dan vektor eigen terkait.

## Teknik Mencari Nilai Eigen Terkecil

Untuk matriks yang dapat diinvertibel, terdapat hubungan penting antara nilai eigen matriks dan inversnya. Jika <InlineMath math="A \cdot v_n = \lambda_n \cdot v_n" />, maka berlaku

<MathContainer>
<BlockMath math="A^{-1} \cdot v_n = \frac{1}{\lambda_n} \cdot v_n" />
</MathContainer>

Artinya, nilai eigen terkecil dari <InlineMath math="A" /> menjadi nilai eigen terbesar dari <InlineMath math="A^{-1}" />. Dengan menerapkan iterasi vektor pada <InlineMath math="A^{-1}" />, kita memperoleh nilai eigen terkecil dari matriks asli.

Praktiknya, setiap iterasi menyelesaikan sistem linear <InlineMath math="A \cdot w_{k+1} = \hat{w}_k" /> menggunakan dekomposisi LU, menghindari perhitungan invers eksplisit yang tidak efisien.